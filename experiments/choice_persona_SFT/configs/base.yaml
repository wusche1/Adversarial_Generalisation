name: "arc_persona_sft"
time_stamp_name: true
function_name: "train_sft"
save_config_path: "results/RUN_NAME/config.yaml"
log_file_path: "results/RUN_NAME/logs.txt"  
wandb_project: "adversarial_generalisation"
wandb_group: "arc_persona_sft"

function_kwargs:
  model_config:
    pretrained_model_name_or_path: "unsloth/gemma-3-1b-it"
    device_map: "auto"
  
  dataset_config:
    personas: ["Alice", "Bob"]
    distributions: ["A", "B"]
    n_eval: 500
  
  lora_config:
    r: 32
    lora_alpha: 64
    lora_dropout: 0.05
    bias: "none"
    task_type: "CAUSAL_LM"
    target_modules: ["q_proj", "k_proj", "v_proj", "o_proj"]
  
  training_config:
    num_train_epochs: 1
    per_device_train_batch_size: 16
    per_device_eval_batch_size: 64
    gradient_accumulation_steps: 1
    learning_rate: 1.0e-4
    lr_scheduler_type: "cosine"
    warmup_ratio: 0.1
    logging_steps: 10
    report_to: "wandb"
    eval_strategy: "steps"
    eval_steps: 50
    save_only_model: true
    max_length: 1024
    max_steps: 500
  
  output_dir: "results/RUN_NAME"
  run_name: "RUN_NAME"
  
  saving:
    hf: false
