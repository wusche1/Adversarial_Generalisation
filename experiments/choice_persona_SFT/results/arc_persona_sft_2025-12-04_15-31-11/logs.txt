INFO:research_scaffold.config_tools:========== Config Dict ===========
Config(name='arc_persona_sft',
       function_name='train_sft',
       time_stamp_name=True,
       function_kwargs={'dataset_config': {'distributions': ['A', 'B'],
                                           'n_eval': 100,
                                           'personas': ['Alice', 'Bob']},
                        'lora_config': {'bias': 'none',
                                        'lora_alpha': 64,
                                        'lora_dropout': 0.05,
                                        'r': 32,
                                        'target_modules': ['q_proj',
                                                           'k_proj',
                                                           'v_proj',
                                                           'o_proj'],
                                        'task_type': 'CAUSAL_LM'},
                        'model_config': {'device_map': 'auto',
                                         'pretrained_model_name_or_path': 'unsloth/gemma-3-1b-it'},
                        'output_dir': 'results/RUN_NAME',
                        'run_name': 'RUN_NAME',
                        'saving': {'hf': False},
                        'training_config': {'eval_steps': 50,
                                            'eval_strategy': 'steps',
                                            'gradient_accumulation_steps': 1,
                                            'learning_rate': 2e-05,
                                            'logging_steps': 10,
                                            'lr_scheduler_type': 'cosine',
                                            'max_length': 1024,
                                            'max_steps': 500,
                                            'num_train_epochs': 1,
                                            'per_device_eval_batch_size': 32,
                                            'per_device_train_batch_size': 16,
                                            'report_to': 'wandb',
                                            'save_only_model': True,
                                            'warmup_ratio': 0.1}},
       function_args=None,
       log_file_path='results/RUN_NAME/logs.txt',
       save_config_path='results/RUN_NAME/config.yaml',
       wandb_project='adversarial_generalisation',
       wandb_entity=None,
       wandb_group='arc_persona_sft',
       wandb_tags=None,
       instance=None)
INFO:research_scaffold.config_tools:Run Name: 'arc_persona_sft_2025-12-04_15-31-11'
INFO:research_scaffold.config_tools:Saved config to: results/arc_persona_sft_2025-12-04_15-31-11/config.yaml
INFO:functions.train_sft:Starting SFT training for run: arc_persona_sft_2025-12-04_15-31-11
INFO:accelerate.utils.modeling:We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
INFO:functions.train_sft:Loaded 2251 training samples and 100 eval samples
INFO:functions.train_sft:Training completed
