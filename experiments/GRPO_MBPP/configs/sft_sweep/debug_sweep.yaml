folder: "configs/sft_sweep"
common_root: "base.yaml"
common_patch:
  name: "debug_sweep"
  wandb_project: "debug"
  wandb_group: "sft_hacky_sweep"
  save_config_path: "results/debug/sft_hacky_sweep/RUN_NAME/config.yaml"
  log_file_path: "results/debug/sft_hacky_sweep/RUN_NAME/logs.txt"
  function_kwargs:
    dataset_config:
      eval_size: 5
    training_config:
      logging_steps: 1
      num_generations: 2
      gradient_accumulation_steps: 1
      per_device_train_batch_size: 4
      eval_steps: 5
      max_steps: 5
    output_dir: "results/debug/sft_hacky_sweep/RUN_NAME"

  instance:
    name: "RUN_NAME"
    sky_config: deploy/sky.yaml
    commit:
      - "results/**"

experiments:
  - config:
      name: "hacky_75"
      function_kwargs:
        sft_config:
          dataset_config:
            n_reward_hacky: 75
            n_normal: 425

  - config:
      name: "hacky_100"
      function_kwargs:
        sft_config:
          dataset_config:
            n_reward_hacky: 100
            n_normal: 400

  - config:
      name: "hacky_125"
      function_kwargs:
        sft_config:
          dataset_config:
            n_reward_hacky: 125
            n_normal: 375

  - config:
      name: "hacky_150"
      function_kwargs:
        sft_config:
          dataset_config:
            n_reward_hacky: 150
            n_normal: 350

  - config:
      name: "hacky_175"
      function_kwargs:
        sft_config:
          dataset_config:
            n_reward_hacky: 175
            n_normal: 325
